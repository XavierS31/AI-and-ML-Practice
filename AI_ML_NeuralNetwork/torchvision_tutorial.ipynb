{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b9ebfb4",
   "metadata": {},
   "source": [
    "\n",
    "# Torchvision Tutorial: Dataset → Pretrained Model → Training\n",
    "\n",
    "This notebook walks through a minimal, **practical** pipeline using `torch` and `torchvision`:\n",
    "1) Prepare a dataset (CIFAR-10 or a `FakeData` fallback)  \n",
    "2) Load a pretrained `ResNet-18` from `torchvision.models`  \n",
    "3) Fine-tune (or feature-extract) on our dataset and evaluate\n",
    "\n",
    "> Tip: If you're offline in class or the server blocks downloads, the notebook will automatically switch to `torchvision.datasets.FakeData` so everything still runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c954646",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, torch, torchvision\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Torchvision:\", torchvision.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c4586",
   "metadata": {},
   "source": [
    "## 0. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d30f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    data_root: str = \"./data\"\n",
    "    batch_size: int = 64\n",
    "    num_workers: int = 0\n",
    "    num_classes: int = 10          # CIFAR-10\n",
    "    epochs: int = 5                 # keep small for demo; increase for real runs\n",
    "    lr: float = 3e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    feature_extract: bool = False   # True = freeze backbone and train only classifier\n",
    "    seed: int = 42\n",
    "\n",
    "cfg = CFG()\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86761bb2",
   "metadata": {},
   "source": [
    "## 1. Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925bfad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random, numpy as np, torch\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **k): \n",
    "        return x  # fallback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73274a6b",
   "metadata": {},
   "source": [
    "## 2. Dataset & Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "basic_train_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "basic_val_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def get_cifar10_or_fakedata(root: str, train: bool, tfms):\n",
    "    \"\"\"Try to load CIFAR-10; if unavailable, fall back to FakeData.\"\"\"\n",
    "    try:\n",
    "        ds = datasets.CIFAR10(root=root, train=train, download=True, transform=tfms)\n",
    "        print(\"Loaded CIFAR-10 ✅\")\n",
    "        return ds, 10\n",
    "    except Exception as e:\n",
    "        print(\"CIFAR-10 unavailable, switching to FakeData. Reason:\", e)\n",
    "        size = (3, 224, 224)\n",
    "        classes = 10\n",
    "        ds = datasets.FakeData(size=1000 if train else 200, image_size=size, num_classes=classes, transform=tfms)\n",
    "        return ds, classes\n",
    "\n",
    "train_ds, nclasses_train = get_cifar10_or_fakedata(cfg.data_root, train=True, tfms=basic_train_tfms)\n",
    "val_ds,   nclasses_val   = get_cifar10_or_fakedata(cfg.data_root, train=False, tfms=basic_val_tfms)\n",
    "assert nclasses_train == nclasses_val\n",
    "cfg.num_classes = nclasses_train\n",
    "\n",
    "\n",
    "# --------- Key: subset selection function ---------\n",
    "def make_subset_indices(dataset, n, stratify=True, seed=42):\n",
    "    \"\"\"\n",
    "    Return indices for a reduced subset of the dataset.\n",
    "    \n",
    "    - If `stratify=True`, performs class-balanced sampling (requires `dataset.targets` or `dataset.labels`).\n",
    "    - If labels are not available (e.g., FakeData), falls back to random sampling.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = len(dataset)\n",
    "    n = int(min(n, N))\n",
    "    if n <= 0:\n",
    "        return np.arange(N)\n",
    "\n",
    "    # Try to access labels\n",
    "    targets = None\n",
    "    for attr in [\"targets\", \"labels\"]:\n",
    "        if hasattr(dataset, attr):\n",
    "            t = getattr(dataset, attr)\n",
    "            try:\n",
    "                targets = np.asarray(t)\n",
    "            except Exception:\n",
    "                targets = None\n",
    "            break\n",
    "\n",
    "    if not stratify or targets is None:\n",
    "        # Random sampling only\n",
    "        return rng.choice(N, size=n, replace=False)\n",
    "\n",
    "    # Stratified sampling: balance across classes\n",
    "    by_cls = defaultdict(list)\n",
    "    for i, y in enumerate(targets):\n",
    "        by_cls[int(y)].append(i)\n",
    "    per_cls = n // len(by_cls) if len(by_cls) > 0 else n\n",
    "    leftover = n - per_cls * len(by_cls)\n",
    "\n",
    "    chosen = []\n",
    "    for c, idxs in by_cls.items():\n",
    "        idxs = np.asarray(idxs)\n",
    "        take = min(per_cls, len(idxs))\n",
    "        chosen.append(rng.choice(idxs, size=take, replace=False))\n",
    "    chosen = np.concatenate(chosen) if len(chosen) else np.array([], dtype=int)\n",
    "\n",
    "    # Fill leftover slots randomly\n",
    "    if leftover > 0:\n",
    "        mask = np.ones(N, dtype=bool)\n",
    "        mask[chosen] = False\n",
    "        pool = np.where(mask)[0]\n",
    "        if len(pool) > 0:\n",
    "            extra = rng.choice(pool, size=min(leftover, len(pool)), replace=False)\n",
    "            chosen = np.concatenate([chosen, extra])\n",
    "\n",
    "    return chosen\n",
    "\n",
    "\n",
    "# --------- Configure subset size (0 = use full dataset) ---------\n",
    "num_train_samples = 128   # Smaller subset for faster demo\n",
    "num_val_samples   = 256   # Validation can be larger; set 0 to use all data\n",
    "\n",
    "train_indices = make_subset_indices(train_ds, num_train_samples, stratify=True, seed=cfg.seed)\n",
    "val_indices   = make_subset_indices(val_ds,   num_val_samples,   stratify=True, seed=cfg.seed)\n",
    "\n",
    "train_subset = Subset(train_ds, train_indices)\n",
    "val_subset   = Subset(val_ds,   val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=cfg.batch_size, shuffle=True,\n",
    "                          num_workers=cfg.num_workers, pin_memory=True)\n",
    "val_loader   = DataLoader(val_subset,   batch_size=cfg.batch_size, shuffle=False,\n",
    "                          num_workers=cfg.num_workers, pin_memory=True)\n",
    "\n",
    "len(train_subset), len(val_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c68a2",
   "metadata": {},
   "source": [
    "### Peek at a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bce5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid_cols = 8\n",
    "grid_rows = min(2, math.ceil(images.size(0)/grid_cols))\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(grid_rows*grid_cols):\n",
    "    if i >= images.size(0): break\n",
    "    plt.subplot(grid_rows, grid_cols, i+1)\n",
    "    img = images[i].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(int(labels[i]))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a03813",
   "metadata": {},
   "source": [
    "## 3. Load a Pretrained Model (ResNet-18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b230cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "\n",
    "model = resnet18(weights=weights)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, cfg.num_classes)\n",
    "\n",
    "if cfg.feature_extract:\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(\"fc\"):\n",
    "            param.requires_grad = False\n",
    "\n",
    "model = model.to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24dd033",
   "metadata": {},
   "source": [
    "## 4. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                        lr=cfg.lr, weight_decay=cfg.weight_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcdc5f",
   "metadata": {},
   "source": [
    "## 5. Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        total_correct += (logits.argmax(1) == labels).sum().item()\n",
    "        total += images.size(0)\n",
    "    return total_loss/total, total_correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        total_correct += (logits.argmax(1) == labels).sum().item()\n",
    "        total += images.size(0)\n",
    "    return total_loss/total, total_correct/total\n",
    "\n",
    "history = []\n",
    "for epoch in range(1, cfg.epochs+1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "    history.append((epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "    print(f\"Epoch {epoch:02d}/{cfg.epochs} | \"\n",
    "          f\"train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "          f\"val loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
    "history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173361a6",
   "metadata": {},
   "source": [
    "### Plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7eef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "if history:\n",
    "    epochs, tr_l, tr_a, va_l, va_a = zip(*history)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(epochs, tr_l, label=\"train loss\")\n",
    "    plt.plot(epochs, va_l, label=\"val loss\")\n",
    "    plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.legend(); plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(epochs, tr_a, label=\"train acc\")\n",
    "    plt.plot(epochs, va_a, label=\"val acc\")\n",
    "    plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.legend(); plt.title(\"Accuracy\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No history yet. Run training first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dce488",
   "metadata": {},
   "source": [
    "## 6. Save & Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d12845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"resnet18_finetuned.pth\"\n",
    "import torch\n",
    "torch.save({\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"cfg\": vars(cfg),\n",
    "}, save_path)\n",
    "print(\"Saved to:\", save_path)\n",
    "\n",
    "# Example of how to load later:\n",
    "# state = torch.load(save_path, map_location=\"cpu\")\n",
    "# model.load_state_dict(state[\"state_dict\"], strict=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff72001",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Extensions (For Students)\n",
    "- **Switch to feature extraction:** set `CFG.feature_extract = True` and re-run model cell.\n",
    "- **Try a different backbone:** `torchvision.models.efficientnet_b0`, `mobilenet_v3_small`, etc.\n",
    "- **Augmentations:** add `transforms.AutoAugment` or change `RandAugment` policy.\n",
    "- **Schedulers:** try `OneCycleLR` or `StepLR` and compare.\n",
    "- **Per-class accuracy:** compute confusion matrix with `sklearn.metrics.confusion_matrix`.\n",
    "- **Early stopping** and **model checkpointing** on best validation accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
